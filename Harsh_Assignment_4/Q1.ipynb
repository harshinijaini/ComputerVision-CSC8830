{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22964d8-8668-4392-9072-8a0e8669b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import depthai as dai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21091343-b5af-4b74-9af7-a7e5a27d550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_IMAGES = 20\n",
    "IMAGES_FOLDER = 'images_folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6db80b-f721-4046-8e62-c3f75acd32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(queue):\n",
    "    frame = queue.get()\n",
    "    return frame.getCvFrame()\n",
    "\n",
    "def getMonoCamera(pipeline, isLeftCamera):\n",
    "    monoCamera = pipeline.createMonoCamera()\n",
    "    monoCamera.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "    if isLeftCamera:\n",
    "        monoCamera.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "    else:\n",
    "        monoCamera.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "    return monoCamera\n",
    "\n",
    "def getColorCamera(pipeline):\n",
    "    colorCamera = pipeline.createColorCamera()\n",
    "    colorCamera.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "    return colorCamera\n",
    "\n",
    "def create_images_folders(imageType):\n",
    "    current_directory = os.getcwd()\n",
    "    sub_images_directory = os.path.join(current_directory, IMAGES_FOLDER+'/'+imageType)\n",
    "    if not os.path.exists(sub_images_directory):\n",
    "        os.makedirs(sub_images_directory)\n",
    "\n",
    "# Create Images Folders\n",
    "create_images_folders('left')\n",
    "create_images_folders('right')\n",
    "create_images_folders('rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0b97d2-9958-4c3a-8b32-44c81155e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dai.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba95f03-cb74-4ca2-ae4f-374f974eacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Capturing Images from Left Camera\n",
    "leftMonoCamera = getMonoCamera(pipeline,isLeftCamera=True)\n",
    "\n",
    "# Creating output\n",
    "xLeftLinkout = pipeline.createXLinkOut()\n",
    "xLeftLinkout.setStreamName('left')\n",
    "leftMonoCamera.out.link(xLeftLinkout.input)\n",
    "\n",
    "with dai.Device(pipeline) as device:\n",
    "    queue_left = device.getOutputQueue(name='left', maxSize=4, blocking=False)\n",
    "    for i in range(NO_OF_IMAGES):\n",
    "        leftFrame = getFrame(queue_left)\n",
    "        cv2.imshow('left', leftFrame)\n",
    "        cv2.imwrite(f\"{IMAGES_FOLDER}/left/left_image_{i+1}.png\", leftFrame)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "    print(f\"Using Left Camera, {NO_OF_IMAGES} images captured\")\n",
    "\n",
    "# Capturing Images from Right Camera\n",
    "rightMonoCamera = getMonoCamera(pipeline,isLeftCamera=False)\n",
    "\n",
    "# Creating output\n",
    "xRightLinkout = pipeline.createXLinkOut()\n",
    "xRightLinkout.setStreamName('right')\n",
    "rightMonoCamera.out.link(xRightLinkout.input)\n",
    "\n",
    "with dai.Device(pipeline) as device:\n",
    "    queue_right = device.getOutputQueue(name='right', maxSize=4, blocking=False)\n",
    "    for i in range(NO_OF_IMAGES):\n",
    "        rightFrame = getFrame(queue_right)\n",
    "        cv2.imshow('right', rightFrame)\n",
    "        cv2.imwrite(f\"{IMAGES_FOLDER}/right/right_image_{i+1}.png\", rightFrame)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "    print(f\"Using Right Camera, {NO_OF_IMAGES} images captured\")\n",
    "\n",
    "# Capturing Images from RGB Camera\n",
    "colorCamera = getColorCamera(pipeline)\n",
    "\n",
    "# Creating output\n",
    "xRGBout = pipeline.createXLinkOut()\n",
    "xRGBout.setStreamName(\"rgb\")\n",
    "colorCamera.video.link(xRGBout.input)\n",
    "with dai.Device(pipeline) as device:\n",
    "    queue_rgb = device.getOutputQueue(name='rgb', maxSize=4, blocking=False)\n",
    "    for i in range(NO_OF_IMAGES):\n",
    "        rgbFrame = getFrame(queue_rgb)\n",
    "        rgbFrameResized = cv.resize(rgbFrame, (960, 540))\n",
    "        cv2.imshow('rgb', rgbFrameResized)\n",
    "        cv2.imwrite(f\"{IMAGES_FOLDER}/rgb/rgb_image_{i+1}.png\", rgbFrame)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "    print(f\"Using RGB Camera, {NO_OF_IMAGES} images captured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f3296-c3c0-47eb-95d1-336efa087cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_calibration(images,imageType):\n",
    "    objectPoints = []\n",
    "    imagePoints = []\n",
    "    \n",
    "    objp = np.zeros((1, 6*9, 3), np.float32)\n",
    "    objp[0,:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "    imagesWithCorner = []\n",
    "    for each_image in images:\n",
    "        img = cv2.imread(each_image)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        retval, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "        if retval == True:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11,11),(-1,-1), termination_criteria)\n",
    "            imgpoints.append(corners2)\n",
    "            img = cv2.drawChessboardCorners(img, (9,6), corners2, retval)\n",
    "            cv2.imshow('img', img)\n",
    "            cv2.imwrite({each_image.split('.')[0]}+\"_corners.png\", img)\n",
    "            cv2.waitKey(1000)\n",
    "            cv2.destroyAllWindows()\n",
    "            imagesWithCorner.append(each_image)\n",
    "    cv2.destroyAllWindows()\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objectPoints, imagePoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    for each_image in images:\n",
    "        img = cv2.imread(each_image)\n",
    "        dst = undistort_image(img, mtx, dist)\n",
    "        # Save the undistorted image\n",
    "        cv2.imwrite(f\"{each_image.split('.')[0]}_result.png\", dst)\n",
    "    \n",
    "    # Saving camera matrix and distortion coefficients\n",
    "    np.savetxt(IMAGES_FOLDER+\"/\"+imageType+\"/camera_matrix.txt\",mtx)\n",
    "    np.savetxt(IMAGES_FOLDER+\"/\"+imageType+\"/distortion_vector.txt\",dist)\n",
    "    np.savetxt(IMAGES_FOLDER+\"/\"+imageType+\"/rotation_vectors.txt\",np.array(rvecs).reshape(-1, 3))\n",
    "    np.savetxt(IMAGES_FOLDER+\"/\"+imageType+\"/translation_vectors.txt\",np.array(tvecs).reshape(-1, 3))\n",
    "    print(\"All camera martix and distortion coefficients are saved\")\n",
    "\n",
    "\n",
    "color_images = glob.glob(IMAGES_FOLDER+'/rgb/*.png')\n",
    "left_images = glob.glob(IMAGES_FOLDER+'/left/*.png')\n",
    "right_images = glob.glob(IMAGES_FOLDER+'/right/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495ffec-95b1-4662-8c20-75731e9eca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_camera_data(camera_matrix_file, distortion_vector_file):\n",
    "    camera_matrix = []\n",
    "    extrinsic_matrix = []\n",
    "    with open(camera_matrix_file, 'r') as f:\n",
    "        for line in f:\n",
    "            camera_matrix.append([float(num) for num in line.split(' ')])\n",
    "    with open(distortion_vector_file, 'r') as f:\n",
    "        for line in f:\n",
    "            extrinsic_matrix.append([float(num) for num in line.split(' ')])\n",
    "    return np.array(camera_matrix), np.array(extrinsic_matrix)\n",
    "\n",
    "def load_stereo_calibration_data():\n",
    "    camera_matrix, extrinsic_matrix = load_camera_data(IMAGES_FOLDER+'/left/camera_matrix.txt', IMAGES_FOLDER+'/left/distortion_vector.txt')\n",
    "    \n",
    "    return camera_matrix, extrinsic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef20626-cea9-4a9a-9cf6-b06ea771c9e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_stereo_calibration_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Load calibration data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     camera_matrix_left, dist_coeffs_left, camera_matrix_right, dist_coeffs_right, R, T \u001b[38;5;241m=\u001b[39m \u001b[43mload_stereo_calibration_data\u001b[49m()\n\u001b[1;32m      8\u001b[0m     baseline \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     10\u001b[0m     cap_left \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Adjust camera index\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_stereo_calibration_data' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main():\n",
    "    # Load calibration data\n",
    "    camera_matrix_left, dist_coeffs_left, camera_matrix_right, dist_coeffs_right, R, T = load_stereo_calibration_data()\n",
    "    baseline = 0.1\n",
    "\n",
    "    cap_left = cv2.VideoCapture(0)  # Adjust camera index\n",
    "    cap_right = cv2.VideoCapture(1)  # Adjust camera index\n",
    "\n",
    "    tracker = setup_tracker()\n",
    "\n",
    "    while True:\n",
    "        ret_left, frame_left = cap_left.read()\n",
    "        ret_right, frame_right = cap_right.read()\n",
    "\n",
    "        success, bbox = tracker.update(frame_left)\n",
    "        if success:\n",
    "            # Drawing bounding box\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame_left, p1, p2, (255,0,0), 2, 1)\n",
    "            \n",
    "            # Estimate dimensions based on the stereo images\n",
    "            width, height, depth = estimate_dimensions(frame_left, frame_right, camera_matrix_left, dist_coeffs_left, camera_matrix_right, dist_coeffs_right, baseline)\n",
    "            print(f\"Dimensions: Width={width}m, Height={height}m, Depth={depth}m\")\n",
    "\n",
    "        # Show the left frame with bounding box and dimensions\n",
    "        cv2.imshow(\"Stereo Object Tracking\", frame_left)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap_left.release()\n",
    "    cap_right.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b73f7-d06b-46fa-8cdb-bf893fd3387f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
