{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2c7164-cb17-44aa-b739-96c8028e488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "\n",
    "NO_OF_IMAGES = 20\n",
    "IMAGES_FOLDER = 'imagesNew'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4294a09-7c55-4854-81f7-7dd7bd4d10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(queue):\n",
    "    frame = queue.get()\n",
    "    return frame.getCvFrame()\n",
    "\n",
    "def getMonoCamera(pipeline, isLeftCamera):\n",
    "    monoCamera = pipeline.createMonoCamera()\n",
    "    monoCamera.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "    if isLeftCamera:\n",
    "        monoCamera.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "    else:\n",
    "        monoCamera.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "    return monoCamera\n",
    "\n",
    "def getColorCamera(pipeline):\n",
    "    colorCamera = pipeline.createColorCamera()\n",
    "    colorCamera.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "    return colorCamera\n",
    "\n",
    "def create_images_folders(imageType):\n",
    "    current_directory = os.getcwd()\n",
    "    sub_images_directory = os.path.join(current_directory, IMAGES_FOLDER+'/'+imageType)\n",
    "    if not os.path.exists(sub_images_directory):\n",
    "        os.makedirs(sub_images_directory)\n",
    "pipeline = dai.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "197379be-c31f-413a-bb09-53e69d191a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/30dsbtvs065f9_1p5klcl8l40000gn/T/ipykernel_18442/4156474464.py:17: DeprecationWarning: LEFT is deprecated, use CAM_B or address camera by name  instead.\n",
      "  monoCamera.setBoardSocket(dai.CameraBoardSocket.LEFT)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Left Camera, 20 images captured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/30dsbtvs065f9_1p5klcl8l40000gn/T/ipykernel_18442/4156474464.py:19: DeprecationWarning: RIGHT is deprecated, use CAM_C or address camera by name  instead.\n",
      "  monoCamera.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Right Camera, 20 images captured\n",
      "Using RGB Camera, 20 images captured\n"
     ]
    }
   ],
   "source": [
    "# Create Images Folders\n",
    "create_images_folders('left')\n",
    "create_images_folders('right')\n",
    "create_images_folders('rgb')\n",
    "\n",
    "\n",
    "# Capturing Images from Left Camera\n",
    "leftMonoCamera = getMonoCamera(pipeline,isLeftCamera=True)\n",
    "\n",
    "# Creating output\n",
    "xLeftLinkout = pipeline.createXLinkOut()\n",
    "xLeftLinkout.setStreamName('left')\n",
    "leftMonoCamera.out.link(xLeftLinkout.input)\n",
    "\n",
    "with dai.Device(pipeline) as device:\n",
    "    queue_left = device.getOutputQueue(name='left', maxSize=4, blocking=False)\n",
    "    for i in range(NO_OF_IMAGES):\n",
    "        leftFrame = getFrame(queue_left)\n",
    "        cv2.imshow('left', leftFrame)\n",
    "        cv2.imwrite(f\"{IMAGES_FOLDER}/left/left_image_{i+1}.png\", leftFrame)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "    print(f\"Using Left Camera, {NO_OF_IMAGES} images captured\")\n",
    "\n",
    "# Capturing Images from Right Camera\n",
    "rightMonoCamera = getMonoCamera(pipeline,isLeftCamera=False)\n",
    "\n",
    "# Creating output\n",
    "xRightLinkout = pipeline.createXLinkOut()\n",
    "xRightLinkout.setStreamName('right')\n",
    "rightMonoCamera.out.link(xRightLinkout.input)\n",
    "\n",
    "with dai.Device(pipeline) as device:\n",
    "    queue_right = device.getOutputQueue(name='right', maxSize=4, blocking=False)\n",
    "    for i in range(NO_OF_IMAGES):\n",
    "        rightFrame = getFrame(queue_right)\n",
    "        cv2.imshow('right', rightFrame)\n",
    "        cv2.imwrite(f\"{IMAGES_FOLDER}/right/right_image_{i+1}.png\", rightFrame)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "    print(f\"Using Right Camera, {NO_OF_IMAGES} images captured\")\n",
    "\n",
    "# Capturing Images from RGB Camera\n",
    "colorCamera = getColorCamera(pipeline)\n",
    "\n",
    "# Creating output\n",
    "xRGBout = pipeline.createXLinkOut()\n",
    "xRGBout.setStreamName(\"rgb\")\n",
    "colorCamera.video.link(xRGBout.input)\n",
    "with dai.Device(pipeline) as device:\n",
    "    queue_rgb = device.getOutputQueue(name='rgb', maxSize=4, blocking=False)\n",
    "    for i in range(NO_OF_IMAGES):\n",
    "        rgbFrame = getFrame(queue_rgb)\n",
    "        rgbFrameResized = cv.resize(rgbFrame, (960, 540))\n",
    "        cv2.imshow('rgb', rgbFrameResized)\n",
    "        cv2.imwrite(f\"{IMAGES_FOLDER}/rgb/rgb_image_{i+1}.png\", rgbFrame)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "    print(f\"Using RGB Camera, {NO_OF_IMAGES} images captured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931dd667-15af-43e4-8126-4a99c96e2093",
   "metadata": {},
   "source": [
    "# Calibrating Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42da4ce7-d55f-4dbb-b396-9432fd609695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagesNew/right/17133958124686\n",
      "imagesNew/right/17133958155687\n",
      "imagesNew/right/17133958052138\n",
      "imagesNew/right/17133958072891\n",
      "imagesNew/right/17133958197161\n",
      "imagesNew/right/17133958062450\n",
      "imagesNew/right/17133958145348\n",
      "imagesNew/right/17133958207539\n",
      "imagesNew/right/17133958217927\n",
      "imagesNew/right/17133958031434\n",
      "imagesNew/right/17133958114348\n",
      "imagesNew/right/17133958083237\n",
      "imagesNew/right/17133958135018\n",
      "imagesNew/right/17133958104004\n",
      "imagesNew/right/17133958166109\n",
      "imagesNew/right/17133958093632\n",
      "imagesNew/right/17133958186820\n",
      "imagesNew/right/17133958176481\n",
      "imagesNew/right/17133958041775\n",
      "Saving camera matrix...\n",
      "Saving distortion vector...\n",
      "Saving rotational vectors...\n",
      "Saving translation vectors...\n",
      "imagesNew/left/17133958277847\n",
      "imagesNew/left/17133958340236\n",
      "imagesNew/left/17133958298571\n",
      "imagesNew/left/17133958381626\n",
      "imagesNew/left/17133958423022\n",
      "imagesNew/left/17133958371271\n",
      "imagesNew/left/17133958329813\n",
      "imagesNew/left/17133958433408\n",
      "imagesNew/left/17133958288161\n",
      "imagesNew/left/17133958402387\n",
      "imagesNew/left/17133958360951\n",
      "imagesNew/left/17133958308971\n",
      "imagesNew/left/17133958391982\n",
      "imagesNew/left/17133958350559\n",
      "imagesNew/left/17133958412709\n",
      "imagesNew/left/17133958319377\n",
      "Saving camera matrix...\n",
      "Saving distortion vector...\n",
      "Saving rotational vectors...\n",
      "Saving translation vectors...\n",
      "imagesNew/rgb/17133960346319\n",
      "imagesNew/rgb/17133960369307\n",
      "imagesNew/rgb/17133960311849\n",
      "imagesNew/rgb/17133960334819\n",
      "imagesNew/rgb/17133960300374\n",
      "imagesNew/rgb/17133960460787\n",
      "imagesNew/rgb/17133960414953\n",
      "imagesNew/rgb/17133960253995\n",
      "imagesNew/rgb/17133960288407\n",
      "imagesNew/rgb/17133960403501\n",
      "imagesNew/rgb/17133960265422\n",
      "imagesNew/rgb/17133960392135\n",
      "imagesNew/rgb/17133960426426\n",
      "imagesNew/rgb/17133960449340\n",
      "imagesNew/rgb/17133960241829\n",
      "imagesNew/rgb/17133960323317\n",
      "imagesNew/rgb/17133960276954\n",
      "imagesNew/rgb/17133960357795\n",
      "imagesNew/rgb/17133960380769\n",
      "imagesNew/rgb/17133960437833\n",
      "Saving camera matrix...\n",
      "Saving distortion vector...\n",
      "Saving rotational vectors...\n",
      "Saving translation vectors...\n"
     ]
    }
   ],
   "source": [
    "# Calibrating\n",
    "termination_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "def undistort_image(img, camera_matrix, distortion_matrix):\n",
    "    h, w = img.shape[:2]\n",
    "    new_camera_mtx, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, distortion_matrix, (w, h), 1, (w, h))\n",
    "    dst = cv2.undistort(img, camera_matrix, distortion_matrix, None, new_camera_mtx)\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    return dst\n",
    "    \n",
    "def perform_calibration(images,imageType):\n",
    "    objectPoints = []\n",
    "    imagePoints = []\n",
    "    \n",
    "    objp = np.zeros((1, 6*9, 3), np.float32)\n",
    "    objp[0,:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "    imagesWithCorner = []\n",
    "    for each_image in images:\n",
    "        img = cv2.imread(each_image)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        retval, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "        if retval == True:\n",
    "            objectPoints.append(objp)\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11,11),(-1,-1), termination_criteria)\n",
    "            imagePoints.append(corners2)\n",
    "            img = cv2.drawChessboardCorners(img, (9,6), corners2, retval)\n",
    "            cv2.imshow('img', img)\n",
    "            print(each_image.split('.')[0])\n",
    "            cv2.imwrite(each_image.split('.')[0]+\"_corners.png\", img)\n",
    "            cv2.waitKey(1000)\n",
    "            cv2.destroyAllWindows()\n",
    "            imagesWithCorner.append(each_image)\n",
    "    cv2.destroyAllWindows()\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objectPoints, imagePoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    for each_image in images:\n",
    "        img = cv2.imread(each_image)\n",
    "        dst = undistort_image(img, mtx, dist)\n",
    "        # Save the undistorted image\n",
    "        cv2.imwrite(f\"{each_image.split('.')[0]}_result.png\", dst)\n",
    "\n",
    "    \n",
    "    # Saving camera matrix and distortion coefficients\n",
    "    np.savetxt(IMAGES_FOLDER+\"/\"+imageType+\"/camera_matrix.txt\",mtx)\n",
    "    np.savetxt(IMAGES_FOLDER+\"/\"+imageType+\"/distortion_vector.txt\",dist)\n",
    "    np.savetxt(IMAGES_FOLDER+\"/\"+imageType+\"/rotation_vectors.txt\",np.array(rvecs).reshape(-1, 3))\n",
    "    np.savetxt(IMAGES_FOLDER+\"/\"+imageType+\"/translation_vectors.txt\",np.array(tvecs).reshape(-1, 3))\n",
    "    print(\"Camera matrix and distortion coefficients are saved\")\n",
    "\n",
    "\n",
    "color_images = glob.glob(IMAGES_FOLDER+'/rgb/*.png')\n",
    "left_images = glob.glob(IMAGES_FOLDER+'/left/*.png')\n",
    "right_images = glob.glob(IMAGES_FOLDER+'/right/*.png')\n",
    "\n",
    "\n",
    "perform_calibration(right_images, 'right')\n",
    "perform_calibration(left_images, 'left')\n",
    "perform_calibration(color_images, 'rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7edd0d-da88-422d-b746-d20cfbcb3200",
   "metadata": {},
   "source": [
    "# Q1) Report the calibration matrix for the camera chosen and verify (using an example) the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ba0709-02f2-4964-98ef-1848c6162a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Square in mm: 17.377797878746254\n",
      "Calibration Error: 12.622202121253746 mm\n"
     ]
    }
   ],
   "source": [
    "def load_camera_data(camera_matrix_file, distortion_vector_file):\n",
    "    camera_matrix = []\n",
    "    extrinsic_matrix = []\n",
    "    with open(camera_matrix_file, 'r') as f:\n",
    "        for line in f:\n",
    "            camera_matrix.append([float(num) for num in line.split(' ')])\n",
    "    with open(distortion_vector_file, 'r') as f:\n",
    "        for line in f:\n",
    "            extrinsic_matrix.append([float(num) for num in line.split(' ')])\n",
    "    return np.array(camera_matrix), np.array(extrinsic_matrix)\n",
    "\n",
    "img_to_undistort = cv2.imread(IMAGES_FOLDER+'/left/17133958308971.png')\n",
    "camera_matrix, extrinsic_matrix = load_camera_data(IMAGES_FOLDER+'/left/camera_matrix.txt', IMAGES_FOLDER+'/left/distortion_vector.txt')\n",
    "undistorted_img = undistort_image(img_to_undistort, camera_matrix, extrinsic_matrix)\n",
    "gray = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2GRAY)\n",
    "known_square_size_mm = 30  # Set the known size of the chessboard square in mm\n",
    "obj_dist = 200  # Set the distance of the object from the camera in mm\n",
    "\n",
    "ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "focal_length_pixels = (camera_matrix[0, 0] + camera_matrix[1, 1]) / 2\n",
    "if ret:\n",
    "    square_size_pixels = np.linalg.norm(corners[3] - corners[4])\n",
    "    square_size_mm = (square_size_pixels / focal_length_pixels) * obj_dist \n",
    "    print(f\"Size of Square in mm: {square_size_mm}\")\n",
    "    calibration_error = abs(square_size_mm - known_square_size_mm)\n",
    "    print(f\"Calibration Error: {calibration_error} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a4eea9-a85f-45cf-b665-e34991370370",
   "metadata": {},
   "source": [
    "# Q2) Computing Rotation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf075d9-41e1-41f8-8fd1-e03929d0bef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic Camera Matrix:\n",
      "[[460.04272191   0.         315.52631449]\n",
      " [  0.         459.75878962 245.91401998]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      "Extrinsic Rotation Matrix:\n",
      "[[ 0.97142518  0.10286102 -0.21389889]\n",
      " [-0.01538436  0.92660434  0.37572292]\n",
      " [ 0.23684688 -0.36169601  0.90170924]] \n",
      "\n",
      "Extrinsic Translation Vector:\n",
      "[[-78.47333184]\n",
      " [-50.74750473]\n",
      " [342.4305318 ]] \n",
      "\n",
      "Rotation Angles across X, Y, Z axes (degrees):\n",
      "[-21.85683944 -13.7005152   -0.90731131] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(IMAGES_FOLDER+'/left/17133958308971.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "if ret:\n",
    "    corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), termination_criteria)\n",
    "    cv2.drawChessboardCorners(img, (9, 6), corners, ret)\n",
    "    cv2.imshow('Corners', img)\n",
    "    cv2.waitKey(5)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Extracting image points\n",
    "top_left_corner = corners[0].ravel()\n",
    "top_right_corner = corners[7].ravel()\n",
    "bottom_right_corner = corners[-1].ravel()\n",
    "bottom_left_corner = corners[-8].ravel()\n",
    "\n",
    "# 2D image points\n",
    "img_points = np.array([top_left_corner, top_right_corner, bottom_right_corner, bottom_left_corner])\n",
    "\n",
    "# Define 3D real-world points\n",
    "obj_points = np.array([[0, 0, 0], [216, 0, 0], [216, 162, 0], [0, 162, 0]], dtype='float32')\n",
    "\n",
    "# Solve PnP\n",
    "ret, rvecs, tvecs = cv2.solvePnP(obj_points, img_points, camera_matrix, extrinsic_matrix)\n",
    "\n",
    "# Convert rotation vectors to rotation matrix\n",
    "rotation_matrix, _ = cv2.Rodrigues(rvecs)\n",
    "\n",
    "# Function to convert rotation matrix to euler angles\n",
    "def rotation_matrix_to_euler_angles(R):\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "# Convert rotation matrix to euler angles\n",
    "euler_angles = np.degrees(rotation_matrix_to_euler_angles(rotation_matrix))\n",
    "\n",
    "# Print results\n",
    "print(\"Intrinsic Camera Matrix:\")\n",
    "print(camera_matrix, \"\\n\")\n",
    "print(\"Extrinsic Rotation Matrix:\")\n",
    "print(rotation_matrix, \"\\n\")\n",
    "print(\"Extrinsic Translation Vector:\")\n",
    "print(tvecs, \"\\n\")\n",
    "print(\"Rotation Angles across X, Y, Z axes (degrees):\")\n",
    "print(euler_angles, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e854e-c2c0-405e-bfe3-01287b60edb7",
   "metadata": {},
   "source": [
    "# Q3) Circular Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772698c7-cf59-484d-bed2-73bfe7bd4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_images_folders('circular_object')\n",
    "# Capturing Circular Object Images from RGB Camera\n",
    "pipeline = dai.Pipeline()\n",
    "colorCamera = getColorCamera(pipeline)\n",
    "\n",
    "# Creating output\n",
    "xRGBout = pipeline.createXLinkOut()\n",
    "xRGBout.setStreamName(\"rgb\")\n",
    "colorCamera.video.link(xRGBout.input)\n",
    "with dai.Device(pipeline) as device:\n",
    "    queue_rgb = device.getOutputQueue(name='rgb', maxSize=4, blocking=False)\n",
    "    for i in range(NO_OF_IMAGES):\n",
    "        rgbFrame = getFrame(queue_rgb)\n",
    "        rgbFrameResized = cv.resize(rgbFrame, (960, 540))\n",
    "        cv2.imshow('rgb', rgbFrameResized)\n",
    "        cv2.imwrite(f\"{IMAGES_FOLDER}/circular_object/circular_object_image_{i+1}.png\", rgbFrame)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "    print(f\"Using RGB Camera, {NO_OF_IMAGES} images captured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fefea140-1c1a-4199-80a0-ee96f9233d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fx: 460.04272190531333, fy: 459.75878962041367, Z: 300\n",
      "Center (x, y): 1028, 408; Width (w): 225; Height (h): 225\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(IMAGES_FOLDER+'/object/circular_object_10.png')\n",
    "object_dist = 300\n",
    "camera_matrix = []\n",
    "with open(IMAGES_FOLDER+'/left/camera_matrix.txt', 'r') as f:\n",
    "    for line in f :\n",
    "        camera_matrix.append([float(num) for num in line.split(' ')])\n",
    "\n",
    "fx, fy, Z = camera_matrix[0][0], camera_matrix[1][1], object_dist\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Using HoughCircles to detect circles\n",
    "circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=50, param1=100, param2=30, minRadius=10, maxRadius=250)\n",
    "\n",
    "circles = circles[0, :]\n",
    "x, y, r = circles[0]\n",
    "center = (int(x), int(y))\n",
    "width = int(2 * r)\n",
    "height = int(2 * r)\n",
    "\n",
    "bbox = (int(x), int(y), width, height)\n",
    "\n",
    "print(f\"fx: {fx}, fy: {fy}, Z: {Z}\")\n",
    "print(f\"Center (x, y): {int(x)}, {int(y)}; Width (w): {width}; Height (h): {height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e2b98f4-e015-438e-a545-a9025ebc40aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real World Co-ordinates: \n",
      "\t 670.3725226273123\n",
      "\t 266.2265578458129\n",
      "\t 817.0980261206442\n",
      "\t 817.6026396588323\n",
      "\n",
      "Diameter of circular object is: 44.93 mm\n"
     ]
    }
   ],
   "source": [
    "def convert_milli_to_inch(x):\n",
    "    x = x / 10\n",
    "    return x / 25.4\n",
    "\n",
    "x, y, w, h = bbox\n",
    "\n",
    "Image_point1x = x\n",
    "Image_point1y = y\n",
    "Image_point2x = x + w\n",
    "Image_point2y = y + h\n",
    "\n",
    "cv2.line(img, (Image_point1x, Image_point1y-h//2), (Image_point1x, Image_point2y-h//2), (0, 0, 255), 8)\n",
    "\n",
    "Real_point1x = Z * (Image_point1x / fx)\n",
    "Real_point1y = Z * (Image_point1y / fy)\n",
    "Real_point2x = Z * (Image_point2x / fx)\n",
    "Real_point2y = Z * (Image_point2x / fy)\n",
    "\n",
    "print(\"Real World Co-ordinates: \")\n",
    "print(\"\\t\", Real_point1x)\n",
    "print(\"\\t\", Real_point1y)\n",
    "print(\"\\t\", Real_point2x)\n",
    "print(\"\\t\", Real_point2y)\n",
    "\n",
    "dist = math.sqrt((Real_point2y - Real_point1y) ** 2 + (Real_point2x - Real_point1x) ** 2)\n",
    "\n",
    "distance = round(convert_milli_to_inch(dist*2)*10, 2)\n",
    "\n",
    "cv2.putText(img, str(distance)+\" mm\", (Image_point1x - 200, (y + h) // 2 + 5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "cv2.imwrite(IMAGES_FOLDER+'/object/circular_object.png', img)\n",
    "print(\"\\nDiameter of circular object is: {} mm\".format(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3705a048-ea17-4cb4-835f-8a6c282a088a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
